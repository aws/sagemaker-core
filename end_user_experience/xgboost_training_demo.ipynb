{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary libraries\n",
    "\n",
    "!pip install -U sagemaker scikit-learn pandas boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role, Session\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get region, role, bucket\n",
    "\n",
    "sagemaker_session = Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Get IRIS Data\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Prepare Data\n",
    "\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "\n",
    "iris_df = iris_df[['target'] + [col for col in iris_df.columns if col != 'target']]\n",
    "\n",
    "train_data, test_data = train_test_split(iris_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data.to_csv('./data/train.csv', index=False, header=False)\n",
    "test_data.to_csv('./data/test.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Upload Data\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "prefix = \"DEMO-scikit-iris\"\n",
    "TRAIN_DATA = \"train.csv\"\n",
    "TEST_DATA = \"test.csv\"\n",
    "WORK_DIRECTORY = \"data\"\n",
    "\n",
    "train_input = sagemaker_session.upload_data(\n",
    "    WORK_DIRECTORY, bucket=bucket, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY)\n",
    ")\n",
    "\n",
    "s3_input_path = \"s3://{}/{}/data/{}\".format(bucket, prefix, TRAIN_DATA)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "print(s3_input_path)\n",
    "print(s3_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "# Fetch XGBOOST image\n",
    "\n",
    "image = image_uris.retrieve(framework='xgboost', region=region, version=\"latest\")\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TrainingJob with Boto3\n",
    "\n",
    "import time\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker')\n",
    "job_name_boto = 'xgboost-iris-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "response = client.create_training_job(\n",
    "    TrainingJobName=job_name_boto,\n",
    "    HyperParameters={\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': '3',\n",
    "        'num_round': '10',\n",
    "        'eval_metric': 'merror'\n",
    "    },\n",
    "    AlgorithmSpecification={\n",
    "        'TrainingImage': image,\n",
    "        'TrainingInputMode': 'File'\n",
    "    },\n",
    "    RoleArn=role,\n",
    "    InputDataConfig=[\n",
    "        {\n",
    "            'ChannelName': 'train',\n",
    "            'ContentType': 'csv',\n",
    "            'DataSource': {\n",
    "                'S3DataSource': {\n",
    "                    'S3DataType': 'S3Prefix',\n",
    "                    'S3Uri': s3_input_path,\n",
    "                    'S3DataDistributionType': 'FullyReplicated'\n",
    "                }\n",
    "            },\n",
    "            'CompressionType': 'None',\n",
    "            'RecordWrapperType': 'None'\n",
    "        }\n",
    "    ],\n",
    "    OutputDataConfig={\n",
    "        'S3OutputPath': s3_output_path\n",
    "    },\n",
    "    ResourceConfig={\n",
    "        'InstanceType': 'ml.m4.xlarge',\n",
    "        'InstanceCount': 1,\n",
    "        'VolumeSizeInGB': 30\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 600\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for TrainingJob with Boto3\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    response = client.describe_training_job(TrainingJobName=job_name_boto)\n",
    "    status = response['TrainingJobStatus']\n",
    "    if status in ['Failed', 'Completed', 'Stopped']:\n",
    "        print(status)\n",
    "        if status == 'Failed':\n",
    "            print(response['FailureReason'])\n",
    "        break\n",
    "    print(\"-\", end=\"\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List TrainingJobs with Boto3\n",
    "import datetime\n",
    "\n",
    "creation_time_after = datetime.datetime.now() - datetime.timedelta(days=1)\n",
    "\n",
    "next_token = None\n",
    "while True:\n",
    "    if next_token:\n",
    "        response = client.list_training_jobs(CreationTimeAfter=creation_time_after, NextToken=next_token)\n",
    "    else: \n",
    "        response = client.list_training_jobs(CreationTimeAfter=creation_time_after)\n",
    "    \n",
    "    for job in response['TrainingJobSummaries']:\n",
    "        print(job['TrainingJobName'])\n",
    "        \n",
    "    next_token = response.get('NextToken')\n",
    "    \n",
    "    if not next_token:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TrainingJob V3\n",
    "\n",
    "import time\n",
    "from src.generated.resources import TrainingJob, AlgorithmSpecification, Channel, DataSource, S3DataSource, \\\n",
    "    OutputDataConfig, ResourceConfig, StoppingCondition\n",
    "\n",
    "job_name_v3 = 'xgboost-iris-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "training_job = TrainingJob.create(\n",
    "    training_job_name=job_name_v3,\n",
    "    hyper_parameters={\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': '3',\n",
    "        'num_round': '10',\n",
    "        'eval_metric': 'merror'\n",
    "    },\n",
    "    algorithm_specification=AlgorithmSpecification(\n",
    "        training_image=image,\n",
    "        training_input_mode='File'\n",
    "    ),\n",
    "    role_arn=role,\n",
    "    input_data_config=[\n",
    "        Channel(\n",
    "            channel_name='train',\n",
    "            content_type='csv',\n",
    "            compression_type='None',\n",
    "            record_wrapper_type='None',\n",
    "            data_source=DataSource(\n",
    "                s3_data_source=S3DataSource(\n",
    "                    s3_data_type='S3Prefix',\n",
    "                    s3_uri=s3_input_path,\n",
    "                    s3_data_distribution_type='FullyReplicated'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    output_data_config=OutputDataConfig(\n",
    "        s3_output_path=s3_output_path\n",
    "    ),\n",
    "    resource_config=ResourceConfig(\n",
    "        instance_type='ml.m4.xlarge',\n",
    "        instance_count=1,\n",
    "        volume_size_in_g_b=30\n",
    "    ),\n",
    "    stopping_condition=StoppingCondition(\n",
    "        max_runtime_in_seconds=600\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for TrainingJob V3\n",
    "\n",
    "training_job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List TrainingJobs V3\n",
    "import datetime\n",
    "from src.generated.resources import TrainingJob\n",
    "\n",
    "creation_time_after = datetime.datetime.now() - datetime.timedelta(days=1)\n",
    "\n",
    "for job in TrainingJob.get_all(creation_time_after=creation_time_after):\n",
    "    print(job.training_job_name, job.training_job_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating TrainingJob using some inputs from Config File - Intelligent Defaults\n",
    "\n",
    "import os\n",
    "import time\n",
    "from src.generated.resources import Cluster, TrainingJob\n",
    "from src.generated.shapes import ClusterInstanceGroupSpecification, ClusterLifeCycleConfig, AlgorithmSpecification, \\\n",
    "    Channel, DataSource, S3DataSource, OutputDataConfig, ResourceConfig, StoppingCondition\n",
    "\n",
    "# Setting path of Config file in environment variable \n",
    "os.environ[\n",
    "    'SAGEMAKER_ADMIN_CONFIG_OVERRIDE'] = '/Users/nargokul/workspace/sagemaker-code-gen/sample/sagemaker/2017-07-24/default-configs.json'\n",
    "\n",
    "# Generating names for resources\n",
    "job_name_v3 = 'xgboost-iris-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "cluster_name_v3 = 'xgboost-cluster-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "# This will create a Cluster - one that does not have default configs in the default-configs.json and will use values from Global Defaults\n",
    "cluster = Cluster.create(\n",
    "    cluster_name=cluster_name_v3,\n",
    "    instance_groups=[ClusterInstanceGroupSpecification(instance_count=1, instance_group_name=\"instance-group-11\",\n",
    "                                                       instance_type=\"ml.m5.4xlarge\",\n",
    "                                                       life_cycle_config=ClusterLifeCycleConfig(\n",
    "                                                           source_s3_uri=s3_input_path, on_create=\"dothis\"),\n",
    "                                                       execution_role=role)\n",
    "                     ]\n",
    ")\n",
    "\n",
    "# This will create a Training Job using specific VPC Config present in the default configs JSON\n",
    "training_job = TrainingJob.create(\n",
    "    training_job_name=job_name_v3,\n",
    "    hyper_parameters={\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': '3',\n",
    "        'num_round': '10',\n",
    "        'eval_metric': 'merror'\n",
    "    },\n",
    "    algorithm_specification=AlgorithmSpecification(\n",
    "        training_image=image,\n",
    "        training_input_mode='File'\n",
    "    ),\n",
    "    role_arn=role,\n",
    "    input_data_config=[\n",
    "        Channel(\n",
    "            channel_name='train',\n",
    "            content_type='csv',\n",
    "            compression_type='None',\n",
    "            record_wrapper_type='None',\n",
    "            data_source=DataSource(\n",
    "                s3_data_source=S3DataSource(\n",
    "                    s3_data_type='S3Prefix',\n",
    "                    s3_uri=s3_input_path,\n",
    "                    s3_data_distribution_type='FullyReplicated'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    output_data_config=OutputDataConfig(\n",
    "        s3_output_path=s3_output_path\n",
    "    ),\n",
    "    resource_config=ResourceConfig(\n",
    "        instance_type='ml.m4.xlarge',\n",
    "        instance_count=1,\n",
    "        volume_size_in_g_b=30\n",
    "    ),\n",
    "    stopping_condition=StoppingCondition(\n",
    "        max_runtime_in_seconds=600\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.generated.shapes import ContainerDefinition, ProductionVariant\n",
    "# Endpoint Invoking \n",
    "from src.generated.resources import Model, EndpointConfig, Endpoint, TrainingJob\n",
    "\n",
    "os.environ[\n",
    "    'SAGEMAKER_ADMIN_CONFIG_OVERRIDE'] = '/Users/nargokul/workspace/sagemaker-code-gen/sample/sagemaker/2017-07-24/default-configs.json'\n",
    "\n",
    "model = Model.create(\n",
    "    model_name='xgboost-iris-5-07',\n",
    "    primary_container=ContainerDefinition(\n",
    "        image='246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:1.7-1',\n",
    "        model_data_url='s3://sagemaker-us-west-2-211125564141/DEMO-scikit-iris/output/xgboost-iris-2024-05-17-02-10-05/output/serve.tar.gz',\n",
    "        # here we are getting model data from the training job \n",
    "        environment={\n",
    "            'LOCAL_PYTHON': '3.10.12',\n",
    "            'MODEL_CLASS_NAME': 'xgboost.sklearn.XGBClassifier',\n",
    "            'SAGEMAKER_CONTAINER_LOG_LEVEL': '10',\n",
    "            'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "            'SAGEMAKER_REGION': 'us-west-2',\n",
    "            'SAGEMAKER_SERVE_SECRET_KEY': '3a459322560a181436866602ddfbb7c16ea97046e92845de43a5ac80f7604451',\n",
    "            'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'\n",
    "        }\n",
    "    ),\n",
    "    execution_role_arn=role,\n",
    ")\n",
    "\n",
    "# model = Model.get(model_name='xgboost-iris')\n",
    "'''\n",
    "if the model is already created then \n",
    "we can use Model.get() to retrive the model\n",
    "'''\n",
    "\n",
    "endpoint_config = EndpointConfig.create(\n",
    "    endpoint_config_name='xgboost-iris-5-07',\n",
    "    production_variants=[\n",
    "        ProductionVariant(\n",
    "            variant_name='xgboost-iris-5-07',\n",
    "            initial_instance_count=1,\n",
    "            instance_type='ml.m5.xlarge',\n",
    "            model_name='xgboost-iris-5-07'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "endpoint: Endpoint = Endpoint.create(\n",
    "    endpoint_name='xgboost-iris-5-07',\n",
    "    endpoint_config_name='xgboost-iris-5-07'  # note we can chain it to get the name automatically\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Invoke the created Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.generated.resources import Endpoint\n",
    "from numpy import loadtxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.base_serializers import NumpySerializer\n",
    "\n",
    "endpoint = Endpoint.get(endpoint_name='xgboost-iris-5-07')\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "dataset = loadtxt('data/pima-indians-diabetes.data.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "serializer = NumpySerializer()\n",
    "\n",
    "\n",
    "def deserialise(response):\n",
    "    return np.load(io.BytesIO(response['Body'].read()))\n",
    "\n",
    "\n",
    "invoke_result = endpoint.invoke(body=serializer.serialize(X_test),\n",
    "                                content_type='application/x-npy',\n",
    "                                accept='application/x-npy')\n",
    "\n",
    "print(\"Endpoint Response:\", deserialise(invoke_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.generated.resources import Endpoint\n",
    "from numpy import loadtxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.base_serializers import NumpySerializer\n",
    "\n",
    "endpoint = Endpoint.get(endpoint_name='xgboost-iris-5-07')\n",
    "dataset = loadtxt('data/pima-indians-diabetes.data.csv', delimiter=\",\")\n",
    "\n",
    "# split data into X and y\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "serializer = NumpySerializer()\n",
    "\n",
    "\n",
    "def deserialise(response):\n",
    "    return [\n",
    "        res_part\n",
    "        for res_part in response['Body']\n",
    "    ]\n",
    "\n",
    "\n",
    "invoke_result = endpoint.invoke_with_response_stream(body=serializer.serialize(X_test),\n",
    "                                                     content_type='application/x-npy',\n",
    "                                                     accept='application/x-npy')\n",
    "\n",
    "print(\"Endpoint Response:\", deserialise(invoke_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
