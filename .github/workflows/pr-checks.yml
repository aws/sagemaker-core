name: PR Checks

on:
  pull_request_target:
    branches:
      - "main*"

permissions:
  id-token: write # This is required for requesting the JWT
  contents: read
  packages: write


jobs:
  collab-check:
    runs-on: ubuntu-latest
    outputs:
      approval-env: ${{ steps.collab-check.outputs.result }}
    steps:
      - name: Collaborator Check
        uses: actions/github-script@v7
        id: collab-check
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          result-encoding: string
          script: |
            try {
              const res = await github.rest.repos.checkCollaborator({
                owner: context.repo.owner,
                repo: context.repo.repo,
                username: "${{ github.event.pull_request.user.login }}",
              });
              console.log("Verifed ${{ github.event.pull_request.user.login }} is a repo collaborator. Auto Approving PR Checks.")
              return res.status == "204" ? "auto-approve" : "manual-approval"
            } catch (error) {
            console.log(error)
              console.log("${{ github.event.pull_request.user.login }} is not a collaborator for "+ context.repo.repo + ".  Requiring Manual Approval to run PR Checks.")
              return "manual-approval"
            }
  wait-for-approval:
    runs-on: ubuntu-latest
    needs: [ collab-check ]
    environment: ${{ needs.collab-check.outputs.approval-env }}
    steps:
      - run: echo "Workflow Approved! Starting Integration tests"
  integ-tests:
    runs-on: ubuntu-latest
    needs: [wait-for-approval]
    strategy:
      fail-fast: false
      matrix:
        python-version: [ "3.12" ]
    env:
      SUBNET_ONE: ${{ secrets.SUBNET_ONE }}
      SUBNET_TWO: ${{ secrets.SUBNET_TWO }}
      SECURITY_GROUP_ONE: ${{ secrets.SECURITY_GROUP_ONE }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha }}
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          export PYTHONPATH="$PYTHONPATH:$PWD"
          python -m pip install --upgrade pip
          pip install scikit-learn sagemaker setuptools awscli
          pip install -e ".[codegen]"
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.INTEG_TEST_ROLE_ARN }}
          aws-region: us-west-2
          role-duration-seconds: 10800
      - name: Run Integration Tests
        id: run-integration-tests
        run: |
          pytest integ
      - name: Put Failure Metrics to CloudWatch
        if: ${{ failure() }}
        run: |
          if [[ "${{ github.event.pull_request.user.login }}" == ${{ secrets.SAGEMAKER_BOT_USER_LOGIN }} ]]; then
            echo "Integration test Failed. Putting Failure Metrics onto Cloudwatch"
            aws cloudwatch put-metric-data --metric-name IntegrationTestFailure --namespace SageMakerPySdkCoreMonitoringMetrics --value 1 --unit Count --dimensions MetricCategory=Integration
          else
            echo "Putting metrics has been skipped"
          fi
      - name: Put Success Metrics to CloudWatch
        if: ${{ success() }}
        run: |
          if [[ "${{ github.event.pull_request.user.login }}" == ${{ secrets.SAGEMAKER_BOT_USER_LOGIN }} ]]; then
            echo "Integration test Succeeded. Putting Success Metrics onto Cloudwatch"
            aws cloudwatch put-metric-data --metric-name IntegrationTestSuccess --namespace SageMakerPySdkCoreMonitoringMetrics --value 1 --unit Count --dimensions MetricCategory=Integration
          else
            echo "Putting metrics has been skipped"
          fi
  unit-tests:
    runs-on: ubuntu-latest
    needs: [wait-for-approval]
    strategy:
      fail-fast: false
      matrix:
        python-version: [ "3.8", "3.9", "3.10", "3.11", "3.12" ]

    steps:
      - uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.sha }}
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          export PYTHONPATH="$PYTHONPATH:$PWD"
          python -m pip install --upgrade pip
          pip install -e ".[codegen]"
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.INTEG_TEST_ROLE_ARN }}
          aws-region: us-west-2
          role-duration-seconds: 10800
      - name: Run Unit Tests
        run: |
          pytest tst
      - name: Put Failure Metrics
        if: ${{ failure() }}
        run: |
          if [[ "${{ github.event.pull_request.user.login }}" == ${{ secrets.SAGEMAKER_BOT_USER_LOGIN }} ]]; then
            echo "Unit test run Failed. Putting Failure Metrics onto Cloudwatch"
            aws cloudwatch put-metric-data --metric-name UnitTestFailure --namespace SageMakerPySdkCoreMonitoringMetrics --value 1 --unit Count --dimensions MetricCategory=Unit-${{ matrix.python-version }}
          else
            echo "Putting metrics has been skipped"
          fi
      - name: Put Success Metrics
        if: ${{ success() }}
        run: |
          if [[ "${{ github.event.pull_request.user.login }}" == ${{ secrets.SAGEMAKER_BOT_USER_LOGIN }} ]]; then
            echo "Unit test run Succeeded. Putting Success Metrics onto Cloudwatch"
            aws cloudwatch put-metric-data --metric-name UnitTestSuccess --namespace SageMakerPySdkCoreMonitoringMetrics --value 1 --unit Count --dimensions MetricCategory=Unit-${{ matrix.python-version }}
          else
            echo "Putting metrics has been skipped"
          fi

  resources-coverage:
    runs-on: ubuntu-latest
    needs: [wait-for-approval]
    strategy:
      fail-fast: false
      matrix:
        python-version: [ "3.12" ]
    steps:
      - uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.sha }}
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.INTEG_TEST_ROLE_ARN }}
          aws-region: us-west-2
          role-duration-seconds: 10800
      - name: Install dependencies
        run: |
          export PYTHONPATH="$PYTHONPATH:$PWD"
          python -m pip install --upgrade pip
          pip install coverage
          pip install pytest-cov
          pip install -e ".[codegen]"
      - name: Run Unit Tests
        run: |
          pytest --cov-report json --cov=src tst/generated/test_resources.py
      - name: Execute Python Coverage compute script and capture output
        id: execute_coverage_parse_script
        run: |
          if [[ "${{ github.event.pull_request.user.login }}" == ${{ secrets.SAGEMAKER_BOT_USER_LOGIN }}* ]]; then
            aws cloudwatch put-metric-data --metric-name UnitTestCoverage --namespace SageMakerPySdkCoreMonitoringMetrics --value $(python workflow_helper/compute_resource_coverage.py) --unit Count --dimensions MetricCategory=Unit-${{ matrix.python-version }}
          else
            echo "Putting metrics has been skipped"
          fi
  put-api-coverage:
    runs-on: ubuntu-latest
    needs: [wait-for-approval]
    steps:
      - uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.sha }}
      - name: Install dependencies
        run: |
          export PYTHONPATH="$PYTHONPATH:$PWD"
          python -m pip install --upgrade pip
          pip install -e ".[codegen]"
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.INTEG_TEST_ROLE_ARN }}
          aws-region: us-west-2
          role-duration-seconds: 10800
      - name: Execute Boto API Coverage compute script and capture output
        run: |
          if [[ "${{ github.event.pull_request.user.login }}" == ${{ secrets.SAGEMAKER_BOT_USER_LOGIN }}* ]]; then
            output=$(python workflow_helper/compute_boto_api_coverage.py)
            unsupported_apis=$(echo $output | cut -d ' ' -f1)
            supported_apis=$(echo $output | cut -d ' ' -f2)
            aws cloudwatch put-metric-data --metric-name UnsupportedAPIs --namespace SageMakerPySdkCoreMonitoringMetrics --value $unsupported_apis --unit Count --dimensions MetricCategory=BotocoreAPICoverage
            aws cloudwatch put-metric-data --metric-name SupportedAPIs --namespace SageMakerPySdkCoreMonitoringMetrics --value $supported_apis --unit Count --dimensions MetricCategory=BotocoreAPICoverage
          else
            echo "Putting metrics has been skipped"
          fi
  pylint-codestyle:
    runs-on: ubuntu-latest
    needs: [wait-for-approval]
    steps:
      - uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.sha }}
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          export PYTHONPATH="$PYTHONPATH:$PWD"
          python -m pip install --upgrade pip
          pip install -e ".[codegen]"
      - name: Run Pylint
        run: |
          python_files=$(find . -name '*.py')
          pylint $python_files --persistent=y --fail-under=8
      - name: Run Black Check
        run: |
          black --check .